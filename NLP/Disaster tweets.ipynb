{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "310d4496-7eef-4ba9-afeb-2bec09d250e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c76a626-c0e3-433f-b9b1-dce58cd945cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "sample_submission=pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb05c72d-d404-4b95-8128-36352d3e48b9",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81abd811-4022-410e-97a7-a3612740e142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "283cfa20-47a0-47a5-95d2-588a097b4e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d2bc2e0-e0ad-4b25-9630-22833426263a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0\n",
       "2   3       0\n",
       "3   9       0\n",
       "4  11       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eed8df1f-6952-46f9-9fb4-99a0541b6eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n",
      "Train dataset Info None \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n",
      "Test dataset Info None \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   id      3263 non-null   int64\n",
      " 1   target  3263 non-null   int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 51.1 KB\n",
      "sample_submission dataset Info None\n"
     ]
    }
   ],
   "source": [
    "print('Train dataset Info',train.info(),'\\n\\n')\n",
    "print('Test dataset Info',test.info(),'\\n\\n')\n",
    "print('sample_submission dataset Info',sample_submission.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac78b52f-c944-490d-b379-8c6d0679778f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4342\n",
       "1    3271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d5d2b9-472d-4195-bced-f7c9d3ac3971",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e63e6e0-4acc-4974-b9d3-e98652973ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= train['text'].values\n",
    "y= train['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b1483ae-5085-4514-93c8-0d44970d2a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all',\n",
       "       'Forest fire near La Ronge Sask. Canada',\n",
       "       \"All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\",\n",
       "       ...,\n",
       "       'M1.94 [01:04 UTC]?5km S of Volcano Hawaii. http://t.co/zDtoyd8EbJ',\n",
       "       'Police investigating after an e-bike collided with a car in Little Portugal. E-bike rider suffered serious non-life threatening injuries.',\n",
       "       'The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/YmY4rSkQ3d'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(x))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb24d29e-4432-4994-9ebd-152479bce23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='For detailed information on text preprocessing methods in NLP, visit https://www.nltk.org/.'\n",
    "def preprocessing(sentence):\n",
    "    \n",
    "       \n",
    "    ###   getting rid of URLs\n",
    "    url_pattern = re.compile(r'http\\S+|www\\S+|https\\S+')\n",
    "    text = re.sub(url_pattern, '', sentence)\n",
    "    \n",
    "    ###   keep only letters\n",
    "    text = re.sub('[^a-zA-Z]',' ',text)\n",
    "\n",
    "    ###  turn all into lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    ### tokenize\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    ###  remove stop words and stemmer\n",
    "    ps = PorterStemmer()\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    all_stopwords.remove('not')\n",
    "    text = [ps.stem(word) for word in text if not word in all_stopwords]\n",
    "\n",
    "    ### lemmatizer\n",
    "    lemma = WordNetLemmatizer()\n",
    "    \n",
    "    text = [lemma.lemmatize(word, wordnet.VERB) for word in text ]\n",
    "    text = [lemma.lemmatize(word, wordnet.ADJ) for word in text ]\n",
    "\n",
    "    \n",
    "    ### join words\n",
    "    text = ' '.join(text)\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ba98499-0800-48d7-9d26-b6584ebaf9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deed reason earthquak may allah forgiv us'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text = preprocessing(str(x[0]))\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d2eb2be-99c5-4b74-a504-381f451475ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].astype(str)\n",
    "train['text'] = train['text'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdb3b785-629c-4e5f-882c-f78b9fa2084c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deed reason earthquak may allah forgiv us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la rong sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>resid ask shelter place notifi offic evacu she...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>peopl receiv wildfir evacu order california</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>get send photo rubi alaska smoke wildfir pour ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN          deed reason earthquak may allah forgiv us   \n",
       "1   4     NaN      NaN               forest fire near la rong sask canada   \n",
       "2   5     NaN      NaN  resid ask shelter place notifi offic evacu she...   \n",
       "3   6     NaN      NaN        peopl receiv wildfir evacu order california   \n",
       "4   7     NaN      NaN  get send photo rubi alaska smoke wildfir pour ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d48fb723-5a5e-4e12-8ef1-205f5f3d9b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f63d9f6-a331-4315-b2aa-480503b463f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6be68d5c-e90f-44bf-b308-4d6407a93e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45db7544-6785-4051-b7a4-de1677b4a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer()\n",
    "#### should pass the column\n",
    "def vectorize(x):\n",
    "    matrix = tf.fit_transform(x.tolist())\n",
    "    return pd.DataFrame(matrix.toarray(),columns = tf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf2883bb-4b25-4991-b55e-3cc3475a42b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized =vectorize(train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05b22129-416c-4d5c-a59d-7e325c19df67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaaaallll</th>\n",
       "      <th>aaaaaand</th>\n",
       "      <th>aaarrrgghhh</th>\n",
       "      <th>aac</th>\n",
       "      <th>aal</th>\n",
       "      <th>aamir</th>\n",
       "      <th>aan</th>\n",
       "      <th>aannnnd</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zotar</th>\n",
       "      <th>zouma</th>\n",
       "      <th>zourryart</th>\n",
       "      <th>zrnf</th>\n",
       "      <th>zss</th>\n",
       "      <th>zumiez</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zxatheti</th>\n",
       "      <th>zzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12864 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aaaa  aaaaaaallll  aaaaaand  aaarrrgghhh  aac  aal  aamir  aan  \\\n",
       "0  0.0   0.0          0.0       0.0          0.0  0.0  0.0    0.0  0.0   \n",
       "1  0.0   0.0          0.0       0.0          0.0  0.0  0.0    0.0  0.0   \n",
       "2  0.0   0.0          0.0       0.0          0.0  0.0  0.0    0.0  0.0   \n",
       "3  0.0   0.0          0.0       0.0          0.0  0.0  0.0    0.0  0.0   \n",
       "4  0.0   0.0          0.0       0.0          0.0  0.0  0.0    0.0  0.0   \n",
       "\n",
       "   aannnnd  ...  zoom  zotar  zouma  zourryart  zrnf  zss  zumiez  zurich  \\\n",
       "0      0.0  ...   0.0    0.0    0.0        0.0   0.0  0.0     0.0     0.0   \n",
       "1      0.0  ...   0.0    0.0    0.0        0.0   0.0  0.0     0.0     0.0   \n",
       "2      0.0  ...   0.0    0.0    0.0        0.0   0.0  0.0     0.0     0.0   \n",
       "3      0.0  ...   0.0    0.0    0.0        0.0   0.0  0.0     0.0     0.0   \n",
       "4      0.0  ...   0.0    0.0    0.0        0.0   0.0  0.0     0.0     0.0   \n",
       "\n",
       "   zxatheti  zzzz  \n",
       "0       0.0   0.0  \n",
       "1       0.0   0.0  \n",
       "2       0.0   0.0  \n",
       "3       0.0   0.0  \n",
       "4       0.0   0.0  \n",
       "\n",
       "[5 rows x 12864 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09ec923b-d978-4193-a62f-81dae867feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "##vectorized['y'] = train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a935f3a4-08a6-4542-aaac-d35c5dab5ec7",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74754ff8-2872-40ae-a502-724c0b07aecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x= vectorized\n",
    "y= train['target']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8ed492e-f15f-4f76-b897-dc5889a729f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_model(x_train,y_train,x_test,y_test,model):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred= model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return y_pred, accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d40249d-af81-43a5-9f01-02feac5308fb",
   "metadata": {},
   "source": [
    "#### naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f38fc1a-434f-4c58-ad12-0b65cf60db26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6007879185817465\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "y_gaussian_pred , gaussian_accuracy = supervised_model(x_train,y_train,x_test,y_test,nb)\n",
    "print(gaussian_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa20abb-fb42-4e52-a0f9-d4c082ec4656",
   "metadata": {},
   "source": [
    "#### logestic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5240e3f5-a48b-41b8-9923-8bb755e85e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7905449770190414\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "y_logestic_reg_pred , logestic_reg_accuracy = supervised_model(x_train,y_train,x_test,y_test,lr)\n",
    "\n",
    "print(logestic_reg_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97131a37-4004-4820-93c3-e916c475d7a4",
   "metadata": {},
   "source": [
    "#### support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f76bee08-bbff-4429-9e27-bf5bee961a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7977675640183848\n"
     ]
    }
   ],
   "source": [
    "svm =SVC()\n",
    "y_svm_pred , svm_accuracy = supervised_model(x_train,y_train,x_test,y_test,svm)\n",
    "print(svm_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08d5be8-af37-410a-9393-2446edd4c9ad",
   "metadata": {},
   "source": [
    "#### neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29c593b5-7f25-4812-b2c5-d23494c8abc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7301378857518056\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier()\n",
    "y_NT_pred , NT_accuracy = supervised_model(x_train,y_train,x_test,y_test,clf)\n",
    "print(NT_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8897c865-61e4-4d40-bf03-4f6c405b2e98",
   "metadata": {},
   "source": [
    "### model evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ce9224d-f28c-421b-bc4a-8888a0498fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(y_test,y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    return accuracy, precision, recall, f1, cm\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0027e7b9-1d16-4778-90c1-0264a5be6622",
   "metadata": {},
   "source": [
    "#### model evaluation for logestic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50823592-f39e-4fd7-88e2-a359fef01a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7905449770190414,\n",
       " 0.7955425218262054,\n",
       " 0.7905449770190414,\n",
       " 0.7854983509963227,\n",
       " array([[786,  88],\n",
       "        [231, 418]], dtype=int64))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluation(y_test,y_logestic_reg_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e941924-06f4-43e5-a839-276a777c7943",
   "metadata": {},
   "source": [
    "#### model evaluation for support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a50d9c20-7362-4a58-b5da-cd00cda9c232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7977675640183848,\n",
       " 0.8065838409974696,\n",
       " 0.7977675640183848,\n",
       " 0.7917093125212229,\n",
       " array([[803,  71],\n",
       "        [237, 412]], dtype=int64))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluation(y_test, y_svm_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db1c31f-afc9-4794-9fb9-6db205e11c51",
   "metadata": {},
   "source": [
    "#### model evaluation for naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c43114e6-774f-4abb-87a7-b9aee10cdb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6007879185817465,\n",
       " 0.6512469727909099,\n",
       " 0.6007879185817465,\n",
       " 0.5941779954698109,\n",
       " array([[401, 473],\n",
       "        [135, 514]], dtype=int64))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluation(y_test, y_gaussian_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb2ce50-32a8-47d3-8213-47158ea87f95",
   "metadata": {},
   "source": [
    "#### model evaluation for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "410da9f7-c62c-4489-8dec-6870ae3043ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7301378857518056,\n",
       " 0.7289110090579581,\n",
       " 0.7301378857518056,\n",
       " 0.7292563811513657,\n",
       " array([[683, 191],\n",
       "        [220, 429]], dtype=int64))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluation(y_test, y_NT_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab84b8d8-2869-4aa1-a261-8c702b580804",
   "metadata": {},
   "source": [
    "#########the best model is the support machine vector or the logestic regression model###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b5e5c1-a20c-4ceb-94ff-3539ba44223c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
